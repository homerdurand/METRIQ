{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "%run dataframes.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lemmatiseur\n",
    "import fr_core_news_md\n",
    "nlp = fr_core_news_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fichier stop word\n",
    "fichier=open('stopwords-fr.txt','r')\n",
    "stops=set()\n",
    "for word in fichier:\n",
    "    mot=re.sub('\\n','',word)\n",
    "    stops.add(mot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de normalisation\n",
    "def normalize(text, stopwords):\n",
    "    lemmatized = list()\n",
    "    text = text.lower()\n",
    "    text_nlp = nlp(text)\n",
    "    for word in text_nlp:\n",
    "        lemma = word.lemma_.strip()\n",
    "        if lemma not in stopwords:\n",
    "            lemmatized.append(lemma)\n",
    "    return \" \".join(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliser(df, stops,support = 'titre'):\n",
    "    dfN = df.copy()\n",
    "    dfN[support] = [normalize(i,stops) for i in dft[support]]\n",
    "    dfN['taille'] = [len(titre) for titre in dft[support]]\n",
    "    return dfN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La concaténation des lettres par semaine:\n",
    "def concatener(df, support = 'titre'):\n",
    "    dfC =  df.groupby(df.index).agg({ support: lambda x: ' '.join(x),'taille': lambda y:np.sum(y)}).rename({support:'concatenation'},axis=1)\n",
    "    dfC['indice'] = dfC.taille.cumsum()\n",
    "    return dfC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les scores du TF-IDF de tous les mots par semaine\n",
    "def multi_scores(df):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    response=vectorizer.fit_transform(df.concatenation)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    dense = response.todense()\n",
    "    denselist = dense.tolist()\n",
    "    return pd.DataFrame(denselist, columns=feature_names).set_index(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction renvoyant le dataframe associé aux nb mots avec les plus grands scores par semaine\n",
    "def premiers_scores(scores, nb):\n",
    "    if nb == 0:\n",
    "        return pd.concat([scores.idxmax(axis=1),scores.max(axis=1)],axis=1).rename(columns ={0:'mot',1:'score'})\n",
    "    data = []\n",
    "    for index, row in scores.iterrows():\n",
    "        data.append(\n",
    "            #[(mot, row[mot]) for mot in row.sort_values(ascending=False)[:5].index]\n",
    "            [mot for mot in row.sort_values(ascending=False)[:nb].index]\n",
    "        )\n",
    "    return pd.DataFrame(data).set_index(scores.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
